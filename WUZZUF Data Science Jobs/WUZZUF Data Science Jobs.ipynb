{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8df8351",
   "metadata": {},
   "source": [
    "<div style=\"padding:20px;\n",
    "            color:white;\n",
    "            margin:10;\n",
    "            font-size:200%;\n",
    "            text-align:center;\n",
    "            display:fill;\n",
    "            border-radius:5px;\n",
    "            background-color:#040465;\n",
    "            overflow:hidden;\n",
    "            font-weight:700\"> Scraping Data Science Jobs in Egypt From WUZZUF </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12056b6d",
   "metadata": {},
   "source": [
    "### <font color=#040465> 1. Import Required Libraries. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f71a18ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  # For making HTTP requests\n",
    "from bs4 import BeautifulSoup  # For web scraping\n",
    "import csv  # For working with CSV files\n",
    "import pandas as pd  # For data analysis and manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad3b399",
   "metadata": {},
   "source": [
    "### <font color=#040465> 2. Send Request & Getting the HTML Code.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8230f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response of Page 1 -- <Response [200]>\n",
      "Response of Page 2 -- <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty string to store all the responses from the web pages\n",
    "all_response = \"\"\n",
    "\n",
    "for idx in range(0, 2):\n",
    "    # Create a URL using an f-string with a dynamic index value\n",
    "    URL = f\"https://wuzzuf.net/search/jobs/?a=spbl&q=data%20science&start={idx}\"\n",
    "    \n",
    "    # Send an HTTP GET request to the URL and store the response\n",
    "    response = requests.get(URL)\n",
    "    \n",
    "    # Print the response status for the current page\n",
    "    print(f\"Response of Page {idx+1} -- {response}\")\n",
    "    \n",
    "    # Append the text content of the response to the 'all_response' string\n",
    "    all_response += response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4874af",
   "metadata": {},
   "source": [
    "<h4 style = \"text-align:center; font-size:100%\">The \"200\" status code specifically indicates a successful HTTP request.</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a34b31b",
   "metadata": {},
   "source": [
    "### <font color=#040465> 3. Creating an HTML Parser Using BeautifulSoup.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "468b3808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a BeautifulSoup object to parse the HTML content with the \"html.parser\" parser\n",
    "soup = BeautifulSoup(all_response, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5015d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## soup.prettify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c313ca89",
   "metadata": {},
   "source": [
    "### <font color=#040465> 4. Creating Container For the Needed Data.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea7adf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "containers = soup.find_all(\"div\" , class_ = \"css-1gatmva e1v1l3u10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bed52480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(containers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42b839db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BeautifulSoup.prettify(containers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca258c61",
   "metadata": {},
   "source": [
    "### <font color=#040465> 5. Accessing Page Elements.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fe4a1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## containers[0].div.h2.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b3c837e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data Science Instructor'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST > scrap the first job title\n",
    "\n",
    "job_title = containers[0].find(\"h2\" , class_ = \"css-m604qf\").get_text()\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3f773bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EpsilonAI'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST > scrap the first company name \n",
    "\n",
    "company_name = containers[0].find(\"a\" , class_ = \"css-17s97q8\").get_text().split()[0]\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63e03eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Full Time'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST > scrap the first job type\n",
    "\n",
    "job_type = containers[0].find(\"span\" , class_ =\"css-1ve4b75 eoyjyou0\").getText()\n",
    "job_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c828e971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nasr City, Cairo, Egypt'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST > the Location of first job\n",
    "\n",
    "location = containers[0].find(\"span\" , class_ = \"css-5wys0k\").get_text().strip()\n",
    "location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5ef33f",
   "metadata": {},
   "source": [
    "### <font color=#040465> 5. Brining it all Together csv File.</font>\n",
    "> **Using CSV Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e7b2b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file called \"data science jobs.csv\" in write mode (\"w\")\n",
    "with open(\"data science jobs.csv\", \"w\") as w:\n",
    "    \n",
    "    # Write the header row with column names\n",
    "    w.write(\"job_title,company_name,location,job_type\\n\")\n",
    "\n",
    "    # Loop through the 'containers' to extract job information\n",
    "    for container in containers:\n",
    "        # Extract job title from the 'container'\n",
    "        job_title = container.find(\"h2\" , class_ = \"css-m604qf\").get_text()\n",
    "        # Replace any commas in the location with slashes\n",
    "        job_title = job_title.replace(\",\",\"/\") if \",\" in job_title else job_title\n",
    "        # Extract company name from the 'container'\n",
    "        company_name = container.find(\"a\" , class_ = \"css-17s97q8\").get_text().split()[0]\n",
    "        # Replace any commas in the location with slashes\n",
    "        company_name = company_name.replace(\",\",\"/\") if \",\" in company_name else company_name\n",
    "        # Extract job type from the 'container'\n",
    "        job_type = container.find(\"span\" , class_ =\"css-1ve4b75 eoyjyou0\").getText()\n",
    "        # Replace any commas in the location with slashes\n",
    "        job_type = job_type.replace(\",\",\"/\") if \",\" in job_type else job_type\n",
    "        # Extract location from the 'container'\n",
    "        location = container.find(\"span\" , class_ = \"css-5wys0k\").get_text().strip() \n",
    "        # Replace any commas in the location with slashes\n",
    "        location = location.replace(\",\",\"/\") if \",\" in location else location\n",
    "\n",
    "        # Write the extracted job information to the CSV file\n",
    "        w.write(f\"{job_title},{company_name},{location},{job_type}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7da9e7e",
   "metadata": {},
   "source": [
    "### <font color=#040465> 6. Check the File.</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3491814c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>job_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Instructor</td>\n",
       "      <td>EpsilonAI</td>\n",
       "      <td>Nasr City/ Cairo/ Egypt</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Architect/Modeler</td>\n",
       "      <td>eT3</td>\n",
       "      <td>New Cairo/ Cairo/ Egypt</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Manager IT Data Engineering</td>\n",
       "      <td>Charterhouse</td>\n",
       "      <td>Dubai/ United Arab Emirates</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analysis Quality Internship - Alexandria</td>\n",
       "      <td>Prometeon</td>\n",
       "      <td>Ameria/ Alexandria/ Egypt</td>\n",
       "      <td>Internship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Snr Data Center Project Engineer</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Dubai/ United Arab Emirates</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Master Data Supervisor</td>\n",
       "      <td>Nahdet</td>\n",
       "      <td>Mohandessin/ Giza/ Egypt</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Specialist Big Data Administrator - SWDC</td>\n",
       "      <td>Giza</td>\n",
       "      <td>Cairo/ Egypt</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analysis Supervisor</td>\n",
       "      <td>Nahdet</td>\n",
       "      <td>Mohandessin/ Giza/ Egypt</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Engineering Data Analyst (Digital Twin)</td>\n",
       "      <td>KBR</td>\n",
       "      <td>Riyadh/ Saudi Arabia</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Engineer-Data Integration</td>\n",
       "      <td>IBM</td>\n",
       "      <td>Cairo/ Egypt</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>DXC.technology</td>\n",
       "      <td>Cairo/ Egypt</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Master Data Analyst</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>Cairo/ Egypt</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Programme Assistant (Data Analyst)</td>\n",
       "      <td>World</td>\n",
       "      <td>Cairo/ Egypt</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>UrbaCon</td>\n",
       "      <td>Doha/ Qatar</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Group Data Engineer</td>\n",
       "      <td>DP</td>\n",
       "      <td>Dubai/ United Arab Emirates</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Erada</td>\n",
       "      <td>Maadi/ Cairo/ Egypt</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Tazweed</td>\n",
       "      <td>Abu Dhabi/ United Arab Emirates</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data Manager / Documents Controller (m/f)</td>\n",
       "      <td>Dornier</td>\n",
       "      <td>Riyadh/ Saudi Arabia</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>QUANT</td>\n",
       "      <td>Riyadh/ Saudi Arabia</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Engineering intern</td>\n",
       "      <td>QUANT</td>\n",
       "      <td>Riyadh/ Saudi Arabia</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Tyde</td>\n",
       "      <td>Dubai/ United Arab Emirates</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>ManpowerGroup</td>\n",
       "      <td>Riyadh/ Saudi Arabia</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Junior Data Analyst</td>\n",
       "      <td>Options</td>\n",
       "      <td>Mohandessin/ Giza/ Egypt</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Architect &amp; Data Lead</td>\n",
       "      <td>ManpowerGroup</td>\n",
       "      <td>Riyadh/ Saudi Arabia</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Solution Architect / Solution Designer - Data/...</td>\n",
       "      <td>Persistence</td>\n",
       "      <td>Riyadh/ Saudi Arabia</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SENIOR DATA WAREHOUSE ANALYST</td>\n",
       "      <td>King</td>\n",
       "      <td>Riyadh/ Saudi Arabia</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Data Engineer lead</td>\n",
       "      <td>BBI-Consultancy</td>\n",
       "      <td>Nasr City/ Cairo/ Egypt</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Data Analysis/Analytics Instructor (Excel - Po...</td>\n",
       "      <td>EpsilonAI</td>\n",
       "      <td>Nasr City/ Cairo/ Egypt</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Carina</td>\n",
       "      <td>New Cairo/ Cairo/ Egypt</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>Alexandria/ Egypt</td>\n",
       "      <td>Full Time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            job_title     company_name  \\\n",
       "0                             Data Science Instructor        EpsilonAI   \n",
       "1                       Senior Data Architect/Modeler              eT3   \n",
       "2                         Manager IT Data Engineering     Charterhouse   \n",
       "3       Data Analysis Quality Internship - Alexandria        Prometeon   \n",
       "4                    Snr Data Center Project Engineer           Amazon   \n",
       "5                              Master Data Supervisor           Nahdet   \n",
       "6            Specialist Big Data Administrator - SWDC             Giza   \n",
       "7                            Data Analysis Supervisor           Nahdet   \n",
       "8             Engineering Data Analyst (Digital Twin)              KBR   \n",
       "9                      Data Engineer-Data Integration              IBM   \n",
       "10                                      Data Engineer   DXC.technology   \n",
       "11                                Master Data Analyst          Johnson   \n",
       "12                 Programme Assistant (Data Analyst)            World   \n",
       "13                                       Data Analyst          UrbaCon   \n",
       "14                                Group Data Engineer               DP   \n",
       "15                                      Data Engineer            Erada   \n",
       "16                                       Data Analyst          Tazweed   \n",
       "17          Data Manager / Documents Controller (m/f)          Dornier   \n",
       "18                                       Data Analyst            QUANT   \n",
       "19                            Data Engineering intern            QUANT   \n",
       "20                                      Data Engineer             Tyde   \n",
       "21                                      Data Engineer    ManpowerGroup   \n",
       "22                                Junior Data Analyst          Options   \n",
       "23                              Architect & Data Lead    ManpowerGroup   \n",
       "24  Solution Architect / Solution Designer - Data/...      Persistence   \n",
       "25                      SENIOR DATA WAREHOUSE ANALYST             King   \n",
       "26                                 Data Engineer lead  BBI-Consultancy   \n",
       "27  Data Analysis/Analytics Instructor (Excel - Po...        EpsilonAI   \n",
       "28                                      Data Engineer           Carina   \n",
       "29                                       Data Analyst     Confidential   \n",
       "\n",
       "                           location    job_type  \n",
       "0           Nasr City/ Cairo/ Egypt   Full Time  \n",
       "1           New Cairo/ Cairo/ Egypt   Full Time  \n",
       "2       Dubai/ United Arab Emirates   Full Time  \n",
       "3         Ameria/ Alexandria/ Egypt  Internship  \n",
       "4       Dubai/ United Arab Emirates   Full Time  \n",
       "5          Mohandessin/ Giza/ Egypt   Full Time  \n",
       "6                      Cairo/ Egypt   Full Time  \n",
       "7          Mohandessin/ Giza/ Egypt   Full Time  \n",
       "8              Riyadh/ Saudi Arabia   Full Time  \n",
       "9                      Cairo/ Egypt   Full Time  \n",
       "10                     Cairo/ Egypt   Full Time  \n",
       "11                     Cairo/ Egypt   Full Time  \n",
       "12                     Cairo/ Egypt   Full Time  \n",
       "13                      Doha/ Qatar   Full Time  \n",
       "14      Dubai/ United Arab Emirates   Full Time  \n",
       "15              Maadi/ Cairo/ Egypt   Full Time  \n",
       "16  Abu Dhabi/ United Arab Emirates   Full Time  \n",
       "17             Riyadh/ Saudi Arabia   Full Time  \n",
       "18             Riyadh/ Saudi Arabia   Full Time  \n",
       "19             Riyadh/ Saudi Arabia   Full Time  \n",
       "20      Dubai/ United Arab Emirates   Full Time  \n",
       "21             Riyadh/ Saudi Arabia   Full Time  \n",
       "22         Mohandessin/ Giza/ Egypt   Full Time  \n",
       "23             Riyadh/ Saudi Arabia   Full Time  \n",
       "24             Riyadh/ Saudi Arabia   Full Time  \n",
       "25             Riyadh/ Saudi Arabia   Full Time  \n",
       "26          Nasr City/ Cairo/ Egypt   Full Time  \n",
       "27          Nasr City/ Cairo/ Egypt   Full Time  \n",
       "28          New Cairo/ Cairo/ Egypt   Full Time  \n",
       "29                Alexandria/ Egypt   Full Time  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = pd.read_csv(\"data science jobs.csv\")\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff536244",
   "metadata": {},
   "source": [
    "<div style=\"padding:20px;\n",
    "            color:white;\n",
    "            margin:10;\n",
    "            font-size:200%;\n",
    "            text-align:center;\n",
    "            display:fill;\n",
    "            border-radius:5px;\n",
    "            background-color:#040465;\n",
    "            overflow:hidden;\n",
    "            font-weight:700\"> Done ✌ </div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
